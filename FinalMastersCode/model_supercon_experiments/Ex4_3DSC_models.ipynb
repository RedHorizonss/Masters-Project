{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from cleaned_code import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from pymatgen.io.cif import CifParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def RFclassifier(features, target, folds = 5):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2)\n",
    "    \n",
    "    # Create a Random Forest classifier\n",
    "    model = RandomForestClassifier(n_estimators=50, max_depth=5, min_samples_leaf=2, min_samples_split=2)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    predictions = model.predict(x_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    class_report = classification_report(y_test, predictions)\n",
    "    \n",
    "    cv_scores = cross_val_score(model, features, target, cv=folds)\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    standard_deviation_cv_scores = np.std(cv_scores)\n",
    "    standard_error = standard_deviation_cv_scores / np.sqrt(folds)\n",
    "    \n",
    "    return model, accuracy, conf_matrix, class_report, mean_cv_score, standard_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFregressor(features, target, \n",
    "                param_grid = {\n",
    "                    'n_estimators': [50, 100, 150],\n",
    "                    'max_depth': [None, 10, 20],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4],\n",
    "                    'max_features': ['log2', 'sqrt']}):\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2)\n",
    "\n",
    "    # Define the RandomForestRegressor model\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, scoring=\"r2\")\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Use the best model for prediction\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(x_test)\n",
    "    feature_importances = best_model.feature_importances_\n",
    "\n",
    "    # Evaluate the model\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return best_model, best_params, mae, mse, rmse, r2, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(importances, features, width=800, height=500):    \n",
    "    # Get the names of the features\n",
    "    feature_names = features.columns.tolist()\n",
    "    feature_names = [name.replace('_', ' ') for name in feature_names]\n",
    "    \n",
    "    # Sort the feature importances in descending order\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Create the bar plot\n",
    "    fig = go.Figure(data=go.Bar(\n",
    "        x=[feature_names[i] for i in indices],\n",
    "        y=importances[indices],\n",
    "        marker_color='rgb(33, 145, 140)', \n",
    "        text= [f'{x:.2f}%' for x in importances[indices]],\n",
    "        textposition='auto'\n",
    "    ))\n",
    "\n",
    "    # Set the layout\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            title=\"Features\",\n",
    "            showline=True,\n",
    "            linewidth=5,\n",
    "            linecolor='black',\n",
    "            ticks='outside',\n",
    "            tickson = \"boundaries\",\n",
    "            tickwidth=3,\n",
    "            ticklen=5\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Feature Importance\",\n",
    "            showline=True,\n",
    "            linewidth=5,\n",
    "            linecolor='black',\n",
    "            ticks='inside',\n",
    "            tickwidth=3,\n",
    "            ticklen=5\n",
    "        ),\n",
    "        barmode='group',\n",
    "        width=width,\n",
    "        height=height,\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        font=dict(family='Helvetica', size=24, color='black'),\n",
    "        margin=dict(l=10, r=10, b=10, t=10),\n",
    "        showlegend=False,\n",
    "        )\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_vs_actual(target_tc, predicted_tc, df):    \n",
    "    df[\"predicted_tc\"] = predicted_tc\n",
    "    \n",
    "        # Define a dictionary to map the old names to the new names\n",
    "    name_mapping = {\n",
    "        'Other': 'Other',\n",
    "        'Not_supercon': 'Not Superconductor',\n",
    "        'Cuprate': 'Cuprate',\n",
    "        'Ferrite': 'Ferrite',\n",
    "        'Heavy_fermion': 'Heavy Fermion',\n",
    "        'Oxide': 'Oxide',\n",
    "        'Chevrel': 'Chevrel',\n",
    "        'Carbon': 'Carbon',\n",
    "        'Heavy_fermionChevrel': 'Heavy Fermion Chevrel',\n",
    "        'OxideHeavy_fermion': 'Oxide Heavy Fermion'\n",
    "    }\n",
    "\n",
    "    # Replace the values in the sc_class column with the new names\n",
    "    df['sc_class_name'] = df['sc_class'].map(name_mapping)\n",
    "    \n",
    "    unique_categories = df[\"sc_class_name\"].unique()\n",
    "\n",
    "    colors = px.colors.qualitative.G10\n",
    "\n",
    "    color_map = {\n",
    "        category: colors[i % len(colors)]\n",
    "        for i, category in enumerate(unique_categories)\n",
    "    }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for category, color in color_map.items():\n",
    "        filtered_df = df[df[\"sc_class_name\"] == category]\n",
    "        trace = go.Scatter(\n",
    "            x=filtered_df[\"tc\"], \n",
    "            y=filtered_df[\"predicted_tc\"], \n",
    "            mode='markers', \n",
    "            text=filtered_df[\"formula_sc\"], \n",
    "            hoverinfo='text',\n",
    "            marker=dict(\n",
    "                color=color,\n",
    "                size=8,  # Adjust marker size as needed\n",
    "                opacity=0.8  # Adjust marker opacity as needed\n",
    "            ),\n",
    "            name=category  # Use category name for legend\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "    # Add y=x line\n",
    "    traces.append(go.Scatter(\n",
    "        x=np.linspace(min(predicted_tc), max(predicted_tc), 100),\n",
    "        y=np.linspace(min(predicted_tc), max(predicted_tc), 100),\n",
    "        mode='lines',\n",
    "        name='y=x',\n",
    "        line=dict(color='black', width=5, dash='dash')\n",
    "    ))\n",
    "\n",
    "    # Create layout\n",
    "    layout = go.Layout(\n",
    "        xaxis=dict(title=\"Real Value\", showline=True, linewidth=5, linecolor='black',\n",
    "                ticks='inside', tickwidth=4, ticklen=5, range=[min(target_tc)-0.5, max(target_tc)+10]),\n",
    "        yaxis=dict(title=\"Predicted Value\", showline=True, linewidth=5, linecolor='black',\n",
    "                ticks='inside', tickwidth=4, ticklen=5, range=[min(predicted_tc)-0.5, max(predicted_tc)+10]),\n",
    "        width=1200,\n",
    "        height=800,\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white', \n",
    "        font=dict(family='Helvetica', size=24, color='black'),\n",
    "        margin=dict(l=10, r=10, b=10, t=10),\n",
    "        legend=dict(orientation=\"v\", yanchor=\"bottom\", y=0, xanchor=\"right\", x=1.5)\n",
    "    )\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MP = pd.read_csv(\"3DSC_MP.csv\", skiprows=1)\n",
    "df_MP['cif'] = df_MP['cif'].str.replace('data/final/MP/', '')\n",
    "df_MP.columns = df_MP.columns.str.replace('_2', '')\n",
    "df_MP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cif_path in df_MP[\"cif\"]:\n",
    "    parser = CifParser(cif_path)\n",
    "    structure = parser.get_structures()[0]  # Assuming there's only one structure in the file\n",
    "\n",
    "    # Get the composition of the structure\n",
    "    composition = structure.composition\n",
    "\n",
    "    # Calculate the average atomic weight\n",
    "    average_atomic_weight = composition.weight\n",
    "    \n",
    "    df_MP.loc[df_MP[\"cif\"] == cif_path, \"average_atomic_weight\"] = average_atomic_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MP_nonzero = df_MP[df_MP[\"tc\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tc = df_MP[\"tc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_features =['num_elements_sc',\n",
    "                    'lata',\n",
    "                    'latb',\n",
    "                    'latc',\n",
    "                    'density',\n",
    "                    'e_above_hull',\n",
    "                    'efermi',\n",
    "                    'final_energy',\n",
    "                    'final_energy_per_atom',\n",
    "                    'formation_energy_per_atom',\n",
    "                    'nsites',\n",
    "                    'cell_volume',\n",
    "                    'exchange_symmetry',\n",
    "                    'true_total_magnetization',\n",
    "                    'average_atomic_weight',\n",
    "                    'totreldiff']\n",
    "\n",
    "df_features = df_MP[physical_features]\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asymcell_features = np.load(\"featurised_datasets\\PHF_AsymCell.npy\")\n",
    "\n",
    "df_features_all = df_features.copy()\n",
    "\n",
    "for i, feature in enumerate(asymcell_features.T):\n",
    "    df_features_all[f\"Feature {i}\"] = np.squeeze(feature)\n",
    "    \n",
    "df_features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PH_features = df_features_all.iloc[:, -18:]\n",
    "PH_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHFS only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_PHFonly = pd.DataFrame(columns=[\"model\", \"mae\" ,\"mse\", \"rmse\", \"r2\", \"n_estimators\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"max_features\", \"feature_importance\"])\n",
    "\n",
    "for i in range(10):\n",
    "    model, best_params, mae, mse, rmse, r2, feature_importances = RFregressor(PH_features, target_tc)\n",
    "    regressor_df_PHFonly = regressor_df_PHFonly.append({\"model\":model,\n",
    "                                                        \"mae\": mae ,\"mse\": mse, \"rmse\": rmse, \"r2\": r2, \n",
    "                                                        \"n_estimators\": best_params[\"n_estimators\"], \"max_depth\": best_params[\"max_depth\"], \n",
    "                                                        \"min_samples_split\": best_params[\"min_samples_split\"], \"min_samples_leaf\": best_params[\"min_samples_leaf\"], \n",
    "                                                        \"max_features\": best_params[\"max_features\"], \n",
    "                                                        \"feature_importance\": feature_importances}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_PHFonly.sort_values(\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_PHFonly.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_PHFonly.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Hyper Paramters:\n",
    "- n_estimators         135.0\n",
    "- max_depth             20.0\n",
    "- min_samples_split      2.0\n",
    "- min_samples_leaf       1.0\n",
    "- max_features           sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_PHFONLY = regressor_df_PHFonly.iloc[regressor_df_PHFonly[\"r2\"].idxmax()][\"model\"]\n",
    "predicted_tc = best_model_PHFONLY.predict(PH_features)\n",
    "\n",
    "plot_predicted_vs_actual(target_tc, predicted_tc, df_MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_array = np.array(regressor_df_PHFonly[\"feature_importance\"].tolist())\n",
    "importances = feature_importance_array.mean(axis=0)\n",
    "plot_feature_importances(importances, PH_features, width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_model(best_model_PHFONLY, PH_features, target_tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_PF = pd.DataFrame(columns=[\"model\", \"mae\" ,\"mse\", \"rmse\", \"r2\", \"n_estimators\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"max_features\", \"feature_importance\"])\n",
    "\n",
    "for i in range(10):\n",
    "    model, best_params, mae, mse, rmse, r2, feature_importances = RFregressor(df_features, target_tc)\n",
    "    regressor_df_PF = regressor_df_PF.append({\"model\":model,\n",
    "                                                \"mae\": mae ,\"mse\": mse, \"rmse\": rmse, \"r2\": r2, \n",
    "                                                \"n_estimators\": best_params[\"n_estimators\"], \"max_depth\": best_params[\"max_depth\"], \n",
    "                                                \"min_samples_split\": best_params[\"min_samples_split\"], \"min_samples_leaf\": best_params[\"min_samples_leaf\"], \n",
    "                                                \"max_features\": best_params[\"max_features\"], \n",
    "                                                \"feature_importance\": feature_importances}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_PF.sort_values(\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_PF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_PF.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Hyper Paramters:\n",
    "- n_estimators         105.0\n",
    "- max_depth             10.0\n",
    "- min_samples_split      3.2\n",
    "- min_samples_leaf       1.4\n",
    "- max_features           sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = regressor_df_PF.iloc[regressor_df_PF[\"r2\"].idxmax()][\"model\"]\n",
    "predicted_tc = best_model.predict(df_features)\n",
    "\n",
    "plot_predicted_vs_actual(target_tc, predicted_tc, df_MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_array_A = np.array(regressor_df_PF[\"feature_importance\"].tolist())\n",
    "importances_A = feature_importance_array_A.mean(axis=0)\n",
    "plot_feature_importances(importances_A, df_features, width=1000, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_model(best_model, df_features, target_tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_all = pd.DataFrame(columns=[\"model\", \"mae\" ,\"mse\", \"rmse\", \"r2\", \"n_estimators\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"max_features\", \"feature_importance\"])\n",
    "\n",
    "for i in range(10):\n",
    "    model, best_params, mae, mse, rmse, r2, feature_importances = RFregressor(df_features_all, target_tc)\n",
    "    regressor_df_all = regressor_df_all.append({\"model\":model,\n",
    "                                                        \"mae\": mae ,\"mse\": mse, \"rmse\": rmse, \"r2\": r2, \n",
    "                                                        \"n_estimators\": best_params[\"n_estimators\"], \"max_depth\": best_params[\"max_depth\"], \n",
    "                                                        \"min_samples_split\": best_params[\"min_samples_split\"], \"min_samples_leaf\": best_params[\"min_samples_leaf\"], \n",
    "                                                        \"max_features\": best_params[\"max_features\"], \n",
    "                                                        \"feature_importance\": feature_importances}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_all.sort_values(\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_all.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Hyper Paramters:\n",
    "- n_estimators         135.0\n",
    "- max_depth             11.0\n",
    "- min_samples_split      2.6\n",
    "- min_samples_leaf       1.2\n",
    "- max_features           sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = regressor_df_all.iloc[regressor_df_all[\"r2\"].idxmax()][\"model\"]\n",
    "predicted_tc = best_model.predict(df_features_all)\n",
    "\n",
    "plot_predicted_vs_actual(target_tc, predicted_tc, df_MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_array_B = np.array(regressor_df_all[\"feature_importance\"].tolist())\n",
    "importances_B = feature_importance_array_B.mean(axis=0)\n",
    "plot_feature_importances(importances_B, df_features_all, width=1200, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing features that have little to no contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With only superconductors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tc_nonzero = df_MP_nonzero[\"tc\"]\n",
    "df_features_nonzero = df_features_all.loc[df_MP_nonzero.index]\n",
    "df_features_nonzero.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_nonzero = pd.DataFrame(columns=[\"model\", \"mae\" ,\"mse\", \"rmse\", \"r2\", \"n_estimators\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"max_features\", \"feature_importance\"])\n",
    "\n",
    "for i in range(10):\n",
    "    model, best_params, mae, mse, rmse, r2, feature_importances = RFregressor(df_features_nonzero, target_tc_nonzero)\n",
    "    regressor_df_nonzero = regressor_df_nonzero.append({\"model\":model,\n",
    "                                                        \"mae\": mae ,\"mse\": mse, \"rmse\": rmse, \"r2\": r2, \n",
    "                                                        \"n_estimators\": best_params[\"n_estimators\"], \"max_depth\": best_params[\"max_depth\"], \n",
    "                                                        \"min_samples_split\": best_params[\"min_samples_split\"], \"min_samples_leaf\": best_params[\"min_samples_leaf\"], \n",
    "                                                        \"max_features\": best_params[\"max_features\"], \n",
    "                                                        \"feature_importance\": feature_importances}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_nonzero.sort_values(\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_nonzero.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_df_nonzero.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Hyper Paramters:\n",
    "- n_estimators         110.0\n",
    "- max_depth             10.0\n",
    "- min_samples_split      5.0\n",
    "- min_samples_leaf       1.1\n",
    "- max_features           sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = regressor_df_nonzero.iloc[regressor_df_all[\"r2\"].idxmax()][\"model\"]\n",
    "predicted_tc = best_model.predict(df_features_nonzero)\n",
    "\n",
    "plot_predicted_vs_actual(target_tc_nonzero, predicted_tc, df_MP_nonzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_array_B = np.array(regressor_df_nonzero[\"feature_importance\"].tolist())\n",
    "importances_B = feature_importance_array_B.mean(axis=0)\n",
    "plot_feature_importances(importances_B, df_features_nonzero, width=1200, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_model(best_model, df_features_nonzero, target_tc_nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MP[\"super_or_not\"] = np.where(df_MP[\"tc\"] == 0, \"Not_supercon\", \"Supercon\") \n",
    "df_MP[\"supercon_or_not_cat\"] = df_MP[\"super_or_not\"].astype('category').cat.codes\n",
    "df_MP[[\"supercon_or_not_cat\", \"super_or_not\", \"formula_sc\", \"tc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, accuracy, conf_matrix, class_report, mean_cv_score, standard_error = RFclassifier(df_features_all, df_MP[\"supercon_or_not_cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Mean CV Score: {mean_cv_score}\")\n",
    "print(f\"Standard Error: {standard_error}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Classification Report:\\n{class_report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
