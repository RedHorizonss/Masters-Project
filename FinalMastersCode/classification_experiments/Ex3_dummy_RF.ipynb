{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from cleaned_code import *\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def RFclassifier(features, target, folds = 5):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2)\n",
    "    \n",
    "    # Create a Random Forest classifier\n",
    "    model = RandomForestClassifier(n_estimators=50, max_depth=5, min_samples_leaf=2, min_samples_split=2)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    predictions = model.predict(x_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    class_report = classification_report(y_test, predictions)\n",
    "    \n",
    "    cv_scores = cross_val_score(model, features, target, cv=folds)\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    standard_deviation_cv_scores = np.std(cv_scores)\n",
    "    standard_error = standard_deviation_cv_scores / np.sqrt(folds)\n",
    "    \n",
    "    return model, accuracy, conf_matrix, class_report, mean_cv_score, standard_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data and clean it, model it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each dataset and store them in a list\n",
    "data_df = pd.DataFrame(columns=['Length', 'Size', \"Accuracy\" ,\"Cross val mean\", \"Cross val error\"])\n",
    "\n",
    "for file_path in glob.glob('dummy_datasets/*.csv'):\n",
    "    unit_cell_size = file_path.split('_')[-3]\n",
    "    dataset_size = file_path.split('_')[-1].split('.')[0]\n",
    "    \n",
    "    dataset = pd.read_csv(file_path)\n",
    "    \n",
    "    features = dataset[dataset.columns[7:]]\n",
    "    target = dataset[\"structure type\"].astype('category').cat.codes\n",
    "    \n",
    "    for i in range(1):\n",
    "        model, accuracy, conf_matrix, class_report, mean_cv_score, standard_error = RFclassifier(features, target)\n",
    "        print(accuracy)\n",
    "        \n",
    "        data_df = data_df.append({'Length': unit_cell_size, 'Size': dataset_size, \"Accuracy\" : accuracy,\n",
    "                                \"Cross val mean\": mean_cv_score, \"Cross val error\": standard_error}, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_grouped_data = data_df.groupby(['Size', 'Length']).mean().reset_index()\n",
    "mean_grouped_data[\"Size\"] = mean_grouped_data[\"Size\"].astype(int)\n",
    "mean_grouped_data[\"Length\"] = mean_grouped_data[\"Length\"].astype(int)\n",
    "mean_grouped_data = mean_grouped_data.sort_values(\"Size\").reset_index(drop = True)\n",
    "\n",
    "std_grouped_data = data_df.groupby(['Size', 'Length']).std().reset_index()\n",
    "std_grouped_data[\"Size\"] = std_grouped_data[\"Size\"].astype(int)\n",
    "std_grouped_data[\"Length\"] = std_grouped_data[\"Length\"].astype(int)\n",
    "std_grouped_data = std_grouped_data.sort_values(\"Size\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "# Create a trace for each length\n",
    "traces = []\n",
    "colors = {0: 'rgb(53, 183, 121)', 1: 'rgb(49, 104, 142)', 2: 'rgb(72, 28, 110)'}  # Specify the colors you want\n",
    "\n",
    "for i, length in enumerate(mean_grouped_data['Length'].unique()):\n",
    "    mean_filtered_data = mean_grouped_data[mean_grouped_data['Length'] == length]\n",
    "    std_filtered_data = std_grouped_data[std_grouped_data['Length'] == length]\n",
    "    \n",
    "    number = mean_filtered_data['Size'].astype(str)\n",
    "    trace = go.Bar(\n",
    "        x=number,\n",
    "        y=mean_filtered_data['Cross val mean'],\n",
    "        name=f'Size: {length}',\n",
    "        error_y=dict(\n",
    "            type='data',\n",
    "            array=mean_filtered_data['Cross val error'],\n",
    "            # array = std_filtered_data['Cross val mean'], if you want to use the standard deviation instead\n",
    "            visible=True,\n",
    "        ),\n",
    "        marker=dict(\n",
    "            color=colors[i]  # Assign the color to each bar\n",
    "        )\n",
    "    )\n",
    "    traces.append(trace)\n",
    "\n",
    "# Create the layout for the plot\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        title=\"Dataset Size\",\n",
    "        showline=True,\n",
    "        linewidth=2,\n",
    "        linecolor='black',\n",
    "        ticks='outside',\n",
    "        tickson = \"boundaries\",\n",
    "        tickwidth=2,\n",
    "        ticklen=5\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Average Cross Val Mean\",\n",
    "        showline=True,\n",
    "        linewidth=2,\n",
    "        linecolor='black',\n",
    "        ticks='inside',\n",
    "        tickwidth=2,\n",
    "        ticklen=5\n",
    "    ),\n",
    "    barmode='group',\n",
    "    width=800,\n",
    "    height=500,\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white',\n",
    "    font=dict(family='Helvetica', size=16, color='black'),\n",
    "    margin=dict(l=10, r=10, b=10, t=10),\n",
    "    legend=dict(\n",
    "        title=dict(\n",
    "            text=\"Unit Cell Size\",\n",
    "            font=dict(\n",
    "                family='Helvetica',\n",
    "                size=16,\n",
    "                color='black'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the figure and add the traces and layout\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these factors dont change the outcome drastically, but the larger the dataset size the more accurate the cross validation score is, addditionally these great values form the cross validation score shows the model is not overfitting and is also producing really great results.\n",
    "\n",
    "This is a much better representation of how well PHFs can work in a model, our superconductor dataset is around 3500 in size and since the unit cell size does not drastically change, I will only test the assymmetric unit cell vs unit cell size 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
