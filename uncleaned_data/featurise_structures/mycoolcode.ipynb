{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to make a fake dataset here to be able to test how featurising these bravais lattices will work with PHF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import structures as st\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy\n",
    "from gtda.diagrams import NumberOfPoints\n",
    "from gtda.diagrams import Amplitude\n",
    "\n",
    "from sklearn.pipeline import make_union, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistence_diagrams(coords):\n",
    "    # Gives data to make persitenace diagrams, need to make code for that\n",
    "    # Track connected components, loops, and voids\n",
    "    homology_dimensions = [0, 1, 2]\n",
    "\n",
    "    # Collapse edges to speed up H2 persistence calculation!\n",
    "    persistence = VietorisRipsPersistence(\n",
    "        metric=\"euclidean\",\n",
    "        homology_dimensions=homology_dimensions,\n",
    "        n_jobs=1,\n",
    "        collapse_edges=True,\n",
    "    )\n",
    "    \n",
    "    reshaped_coords=coords[None, :, :]\n",
    "    diagrams_basic = persistence.fit_transform(reshaped_coords)\n",
    "    return coords, diagrams_basic\n",
    "\n",
    "def make_pipeline():\n",
    "\n",
    "    metrics = [\n",
    "        {\"metric\": metric}\n",
    "        for metric in [\"bottleneck\", \"wasserstein\", \"landscape\", \"persistence_image\"]\n",
    "    ]\n",
    "\n",
    "    # Concatenate to generate 3 + 3 + (4 x 3) = 18 topological features\n",
    "    feature_union = make_union(\n",
    "        PersistenceEntropy(normalize=True),\n",
    "        NumberOfPoints(n_jobs=1),\n",
    "        *[Amplitude(**metric, n_jobs=1) for metric in metrics]\n",
    "    )\n",
    "\n",
    "    ## then we use a pipeline to transform, the data and spit i out\n",
    "    # mwah hahahahaha\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"features\", feature_union)\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "    return pipe\n",
    "\n",
    "def featurising_coords(coords_of_structures):\n",
    "    topol_feat_list = []\n",
    "    pipe = make_pipeline()\n",
    "\n",
    "    for coords in coords_of_structures:\n",
    "        _ , diagrams_basic = persistence_diagrams(coords)\n",
    "        X_basic = pipe.fit_transform(diagrams_basic)\n",
    "        # topology feat list stores the topological features for each structure\n",
    "        topol_feat_list.append([x for x in X_basic[0]])\n",
    "    \n",
    "    # topol feat mat is a matrix of topological features\n",
    "    topol_feat_mat = np.array(topol_feat_list)\n",
    "    \n",
    "    return topol_feat_mat, topol_feat_list\n",
    "\n",
    "def do_random_forest(features, target):\n",
    "    # we need to binarize the labels\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    features_transformed = mlb.fit_transform(features)\n",
    "\n",
    "    x_train, x_test ,y_train, y_test = train_test_split(features_transformed,target,test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    accuracy = round(model.score(x_test, y_test) * 100, 2)\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomise_sides(length, num_of_diff_sides):\n",
    "    sides_df = pd.DataFrame(columns=['a', 'b', 'c'])\n",
    "    \n",
    "    while len(sides_df) < length:\n",
    "        side_a = round(np.random.uniform(3, 9.0), 3)\n",
    "        if num_of_diff_sides == 1:\n",
    "            side_b = side_a\n",
    "            side_c  = round(np.random.uniform(3, 9.0), 3)\n",
    "            \n",
    "            if side_a != side_c:\n",
    "                sides_df = sides_df.append({'a': side_a, 'b': side_b, 'c': side_c}, ignore_index=True)\n",
    "            \n",
    "        elif num_of_diff_sides == 2:\n",
    "            side_b = round(np.random.uniform(3, 9.0), 3)\n",
    "            side_c  = round(np.random.uniform(3, 9.0), 3)\n",
    "            \n",
    "            if side_a != side_b != side_c:\n",
    "                sides_df = sides_df.append({'a': side_a, 'b': side_b, 'c': side_c}, ignore_index=True)\n",
    "                \n",
    "        else:\n",
    "            side_b = side_a\n",
    "            side_c = side_a\n",
    "            sides_df = sides_df.append({'a': side_a, 'b': side_b, 'c': side_c}, ignore_index=True)\n",
    "            \n",
    "    return sides_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomise_angles(length, randomise_1, randomise_3, same_3_randomised):\n",
    "    if randomise_1 == True:\n",
    "        angles = []\n",
    "        while len(angles) < length:\n",
    "            ang_a = np.random.uniform(45, 80)\n",
    "            ang_a = round(ang_a, 1)\n",
    "            angles.append(ang_a)\n",
    "            \n",
    "    elif randomise_3 == True:\n",
    "        angles = []\n",
    "        while len(angles) < length:\n",
    "            ang_a = np.random.uniform(45, 80)\n",
    "            ang_a = round(ang_a, 1)\n",
    "            ang_b = np.random.uniform(45, 80)\n",
    "            ang_b = round(ang_b, 1)\n",
    "            ang_y = np.random.uniform(45, 80)\n",
    "            ang_y = round(ang_y, 1)\n",
    "            \n",
    "            if ang_a != ang_b != ang_y:\n",
    "                angles.append([ang_a, ang_b, ang_y])\n",
    "                \n",
    "    elif same_3_randomised == True:\n",
    "        angles = []\n",
    "        while len(angles) < length:\n",
    "            ang_a = np.random.uniform(45, 80)\n",
    "            ang_a = round(ang_a, 1)\n",
    "            ang_b = ang_a\n",
    "            ang_y = ang_a\n",
    "            \n",
    "            angles.append([ang_a, ang_b, ang_y])\n",
    "            \n",
    "    else:\n",
    "        print('Please choose a valid option')\n",
    "        \n",
    "    return angles\n",
    "\n",
    "# try_ang = randomise_angles(10, False, True, False)\n",
    "# try_ang_df = pd.DataFrame(try_ang, columns=['angle_a', 'angle_b', 'angle_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(a, b, c, alpha, beta, gamma, name):\n",
    "    data = {\n",
    "        'a': a,\n",
    "        'b': b,\n",
    "        'c': c,\n",
    "        'alpha': alpha,\n",
    "        'beta': beta,\n",
    "        'gamma': gamma,\n",
    "        'structure type': name\n",
    "        }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dataframe\n",
    "data_df = pd.DataFrame(columns=['Length', 'Size', 'F1 Score', 'Precision', 'Recall', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [100, 200, 400, 600, 800, 1000]\n",
    "unit_cell_size = [2, 3, 4]\n",
    "for length in lengths:\n",
    "    for size in unit_cell_size:\n",
    "        sides = randomise_sides(length, 0)\n",
    "        cubic = make_dataset(sides[\"a\"], sides[\"b\"], sides[\"c\"], 90, 90, 90, \"cubic\")\n",
    "\n",
    "        sides = randomise_sides(length, 0)\n",
    "        hexagonal = make_dataset(sides[\"a\"], sides[\"b\"], sides[\"c\"], 90, 90, 120, \"hexagonal\")\n",
    "\n",
    "        sides = randomise_sides(length, 1)\n",
    "        tetragonal = make_dataset(sides[\"a\"], sides[\"b\"], sides[\"c\"], 90, 90, 90, \"tetragonal\")\n",
    "\n",
    "        sides = randomise_sides(length, 2)\n",
    "        orthorhombic = make_dataset(sides[\"a\"], sides[\"b\"], sides[\"c\"], 90, 90, 90, \"orthorhombic\")\n",
    "\n",
    "        sides = randomise_sides(length, 0)\n",
    "        angles = randomise_angles(length, False, False, True)\n",
    "        angles = pd.DataFrame(angles, columns=['alpha', 'beta', 'gamma'])\n",
    "        rhomobohedral = make_dataset(sides[\"a\"], sides[\"b\"], sides[\"c\"], angles[\"alpha\"], \n",
    "                                    angles[\"beta\"], angles[\"gamma\"], \"rhomobohedral\")\n",
    "\n",
    "        sides = randomise_sides(length, 2)\n",
    "        angles = randomise_angles(length, True, False, False)\n",
    "        monoclinc = make_dataset(sides[\"a\"], sides[\"b\"], sides[\"c\"], 90, angles, 90, \"monoclinc\")\n",
    "\n",
    "        sides = randomise_sides(length, 2)\n",
    "        angles = randomise_angles(length, False, True, False)\n",
    "        angles = pd.DataFrame(angles, columns=['alpha', 'beta', 'gamma'])\n",
    "\n",
    "        triclinic = make_dataset(sides[\"a\"], sides[\"b\"], sides[\"c\"],\n",
    "                                    angles[\"alpha\"], angles[\"beta\"], angles[\"gamma\"], \"triclinic\")\n",
    "\n",
    "        final_df = pd.concat([cubic, hexagonal, rhomobohedral, tetragonal, orthorhombic, monoclinc, triclinic],ignore_index=True)\n",
    "\n",
    "        coords = []\n",
    "        for index, row in final_df.iterrows():\n",
    "            coords.append(st.Structure(size,size,size,\n",
    "                                    row[\"a\"] ,row[\"b\"], row[\"c\"], \n",
    "                                    row[\"alpha\"], row[\"beta\"], row[\"gamma\"],\n",
    "                                    False, False, False))\n",
    "            \n",
    "        matrix_list, feat_cryst_list = featurising_coords(coords_of_structures=coords)\n",
    "        final_df['Crystals Featurised'] = feat_cryst_list\n",
    "\n",
    "        final_df[\"Lowest distortion\"] = final_df[\"structure type\"].astype('category')\n",
    "        final_df[\"Lowest distortion Categories\"] = final_df[\"Lowest distortion\"].cat.codes\n",
    "        \n",
    "        f1, precision, recall, accuracy = do_random_forest(final_df[\"Crystals Featurised\"], final_df[\"Lowest distortion Categories\"])\n",
    "        \n",
    "        data_df = data_df.append({'Length': length*7, 'Size': size, 'F1 Score': f1, 'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Size</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.116998</td>\n",
       "      <td>0.222795</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>25.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.115915</td>\n",
       "      <td>0.207503</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>25.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.116702</td>\n",
       "      <td>0.243861</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>25.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.120228</td>\n",
       "      <td>0.077288</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>27.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1400.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.147984</td>\n",
       "      <td>0.341981</td>\n",
       "      <td>0.289286</td>\n",
       "      <td>28.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.120228</td>\n",
       "      <td>0.077288</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>27.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.175052</td>\n",
       "      <td>0.408134</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>29.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.159632</td>\n",
       "      <td>0.509506</td>\n",
       "      <td>0.289286</td>\n",
       "      <td>28.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2800.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.172564</td>\n",
       "      <td>0.419009</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.197394</td>\n",
       "      <td>0.397923</td>\n",
       "      <td>0.311905</td>\n",
       "      <td>31.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4200.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.216082</td>\n",
       "      <td>0.581046</td>\n",
       "      <td>0.323810</td>\n",
       "      <td>32.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.201887</td>\n",
       "      <td>0.564832</td>\n",
       "      <td>0.313095</td>\n",
       "      <td>31.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.177078</td>\n",
       "      <td>0.556721</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.187711</td>\n",
       "      <td>0.568687</td>\n",
       "      <td>0.302679</td>\n",
       "      <td>30.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.203177</td>\n",
       "      <td>0.684343</td>\n",
       "      <td>0.309821</td>\n",
       "      <td>30.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.188828</td>\n",
       "      <td>0.540687</td>\n",
       "      <td>0.302857</td>\n",
       "      <td>30.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.190629</td>\n",
       "      <td>0.618906</td>\n",
       "      <td>0.301429</td>\n",
       "      <td>30.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.210762</td>\n",
       "      <td>0.572550</td>\n",
       "      <td>0.312143</td>\n",
       "      <td>31.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Length  Size  F1 Score  Precision    Recall  Accuracy\n",
       "0    700.0   2.0  0.116998   0.222795  0.257143     25.71\n",
       "1    700.0   3.0  0.115915   0.207503  0.257143     25.71\n",
       "2    700.0   4.0  0.116702   0.243861  0.257143     25.71\n",
       "3   1400.0   2.0  0.120228   0.077288  0.275000     27.50\n",
       "4   1400.0   3.0  0.147984   0.341981  0.289286     28.93\n",
       "5   1400.0   4.0  0.120228   0.077288  0.275000     27.50\n",
       "6   2800.0   2.0  0.175052   0.408134  0.294643     29.46\n",
       "7   2800.0   3.0  0.159632   0.509506  0.289286     28.93\n",
       "8   2800.0   4.0  0.172564   0.419009  0.300000     30.00\n",
       "9   4200.0   2.0  0.197394   0.397923  0.311905     31.19\n",
       "10  4200.0   3.0  0.216082   0.581046  0.323810     32.38\n",
       "11  4200.0   4.0  0.201887   0.564832  0.313095     31.31\n",
       "12  5600.0   2.0  0.177078   0.556721  0.300000     30.00\n",
       "13  5600.0   3.0  0.187711   0.568687  0.302679     30.27\n",
       "14  5600.0   4.0  0.203177   0.684343  0.309821     30.98\n",
       "15  7000.0   2.0  0.188828   0.540687  0.302857     30.29\n",
       "16  7000.0   3.0  0.190629   0.618906  0.301429     30.14\n",
       "17  7000.0   4.0  0.210762   0.572550  0.312143     31.21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df1 = data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
